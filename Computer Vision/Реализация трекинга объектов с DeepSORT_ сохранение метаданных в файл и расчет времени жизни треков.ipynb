{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"x5LjYMHR-4bD","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1748625298406,"user_tz":-180,"elapsed":4153,"user":{"displayName":"Nikolay Bukin","userId":"12801653507391334847"}},"outputId":"bea1e639-be0f-49a9-95d1-dffd17bf31a0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ikomia in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (from ikomia) (3.0.12)\n","Requirement already satisfied: setuptools==73.0.1 in /usr/local/lib/python3.11/dist-packages (from ikomia) (73.0.1)\n","Requirement already satisfied: numpy<2.0,>=1.24.4 in /usr/local/lib/python3.11/dist-packages (from ikomia) (1.26.4)\n","Requirement already satisfied: requests<3.0,>=2.28.0 in /usr/local/lib/python3.11/dist-packages (from ikomia) (2.32.3)\n","Requirement already satisfied: mlflow<3.0,>=2.17.2 in /usr/local/lib/python3.11/dist-packages (from ikomia) (2.22.0)\n","Requirement already satisfied: tensorboard<3.0,>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from ikomia) (2.18.0)\n","Requirement already satisfied: Pillow>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from ikomia) (11.2.1)\n","Requirement already satisfied: tqdm<5.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from ikomia) (4.67.1)\n","Requirement already satisfied: matplotlib<4.0,>=3.4.3 in /usr/local/lib/python3.11/dist-packages (from ikomia) (3.10.0)\n","Requirement already satisfied: python-dotenv>=0.18.0 in /usr/local/lib/python3.11/dist-packages (from ikomia) (1.1.0)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from ikomia) (6.0.2)\n","Requirement already satisfied: semver<4.0,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from ikomia) (3.0.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0,>=3.4.3->ikomia) (2.9.0.post0)\n","Requirement already satisfied: mlflow-skinny==2.22.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (2.22.0)\n","Requirement already satisfied: Flask<4 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (3.1.1)\n","Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (3.1.6)\n","Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (1.16.1)\n","Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (7.1.0)\n","Requirement already satisfied: graphene<4 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (3.4.3)\n","Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (23.0.0)\n","Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (3.8)\n","Requirement already satisfied: pandas<3 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (2.2.2)\n","Requirement already satisfied: pyarrow<20,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (18.1.0)\n","Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (1.6.1)\n","Requirement already satisfied: scipy<2 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (1.15.3)\n","Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow<3.0,>=2.17.2->ikomia) (2.0.41)\n","Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (5.5.2)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (8.2.1)\n","Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (3.1.1)\n","Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.55.0)\n","Requirement already satisfied: fastapi<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.115.12)\n","Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (3.1.44)\n","Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (8.6.1)\n","Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (1.33.1)\n","Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (1.33.1)\n","Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (5.29.4)\n","Requirement already satisfied: pydantic<3,>=1.10.8 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (2.11.4)\n","Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.5.3)\n","Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (4.13.2)\n","Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.11/dist-packages (from mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.34.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.28.0->ikomia) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.28.0->ikomia) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.28.0->ikomia) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0,>=2.28.0->ikomia) (2025.4.26)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.71.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<3.0,>=2.5.0->ikomia) (3.1.3)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic!=1.10.0,<2->mlflow<3.0,>=2.17.2->ikomia) (1.1.3)\n","Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow<3.0,>=2.17.2->ikomia) (1.9.0)\n","Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow<3.0,>=2.17.2->ikomia) (2.2.0)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Flask<4->mlflow<3.0,>=2.17.2->ikomia) (3.0.2)\n","Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow<3.0,>=2.17.2->ikomia) (3.2.6)\n","Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.11/dist-packages (from graphene<4->mlflow<3.0,>=2.17.2->ikomia) (3.2.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow<3.0,>=2.17.2->ikomia) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3->mlflow<3.0,>=2.17.2->ikomia) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow<3.0,>=2.17.2->ikomia) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2->mlflow<3.0,>=2.17.2->ikomia) (3.6.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow<3.0,>=2.17.2->ikomia) (3.2.2)\n","Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.11/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (2.38.0)\n","Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi<1->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.46.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (4.0.12)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (3.21.0)\n","Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (1.2.18)\n","Requirement already satisfied: opentelemetry-semantic-conventions==0.54b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.54b1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (2.33.2)\n","Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.4.1)\n","Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<1->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.16.0)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (1.17.2)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (5.0.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.4.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (4.9.1)\n","Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (4.9.0)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<1->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (1.3.1)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.22.0->mlflow<3.0,>=2.17.2->ikomia) (0.6.1)\n"]}],"source":["!pip install ikomia"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qQ67UKJWDFKV","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1748625306972,"user_tz":-180,"elapsed":8564,"user":{"displayName":"Nikolay Bukin","userId":"12801653507391334847"}},"outputId":"cb598876-d90d-4c11-8a18-023988f629b3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.146-py3-none-any.whl.metadata (37 kB)\n","Collecting deep_sort_realtime\n","  Downloading deep_sort_realtime-1.3.2-py3-none-any.whl.metadata (12 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.26.4)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.1.2+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.16.2+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.1.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Downloading ultralytics-8.3.146-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading deep_sort_realtime-1.3.2-py3-none-any.whl (8.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: deep_sort_realtime, ultralytics-thop, ultralytics\n","Successfully installed deep_sort_realtime-1.3.2 ultralytics-8.3.146 ultralytics-thop-2.0.14\n"]}],"source":["!pip install ultralytics deep_sort_realtime"]},{"cell_type":"markdown","metadata":{"id":"jXkZMXydW3H9"},"source":["# Задача 1"]},{"cell_type":"markdown","metadata":{"id":"eb5DX09TW6pL"},"source":["На основе алгоритма DeepSORT реализуйте возможность подсчета количества объектов и какого класса пересекает заданную линию в обеих направлениях."]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2t2rvWrDMGz0","executionInfo":{"status":"ok","timestamp":1748625313622,"user_tz":-180,"elapsed":2390,"user":{"displayName":"Nikolay Bukin","userId":"12801653507391334847"}},"outputId":"4763eed0-300b-45f4-8c36-6e6dc721cccf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fVqW5rcWC71B"},"outputs":[],"source":["def ccw(A, B, C):\n","    \"\"\"Проверка направления поворота\"\"\"\n","    return (C[1]-A[1]) * (B[0]-A[0]) > (B[1]-A[1]) * (C[0]-A[0])\n","\n","def intersect(A, B, C, D):\n","    \"\"\"Пересекаются ли отрезки AB и CD\"\"\"\n","    return ccw(A, C, D) != ccw(B, C, D) and ccw(A, B, C) != ccw(A, B, D)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eqeEkBRp-kjt","outputId":"b7af9fde-ab52-402e-b62c-cd7031d32565","executionInfo":{"status":"ok","timestamp":1748625620762,"user_tz":-180,"elapsed":220197,"user":{"displayName":"Nikolay Bukin","userId":"12801653507391334847"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 6.25M/6.25M [00:00<00:00, 16.4MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 7 cars, 1 truck, 252.3ms\n","Speed: 9.6ms preprocess, 252.3ms inference, 23.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 198.7ms\n","Speed: 3.2ms preprocess, 198.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 188.5ms\n","Speed: 3.0ms preprocess, 188.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 199.3ms\n","Speed: 3.3ms preprocess, 199.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 204.0ms\n","Speed: 3.2ms preprocess, 204.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 124.2ms\n","Speed: 2.9ms preprocess, 124.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 128.2ms\n","Speed: 3.8ms preprocess, 128.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 132.5ms\n","Speed: 3.1ms preprocess, 132.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 127.5ms\n","Speed: 3.8ms preprocess, 127.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 127.5ms\n","Speed: 3.2ms preprocess, 127.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 152.4ms\n","Speed: 3.1ms preprocess, 152.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 149.9ms\n","Speed: 3.5ms preprocess, 149.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 151.1ms\n","Speed: 4.0ms preprocess, 151.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 125.2ms\n","Speed: 4.5ms preprocess, 125.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 128.9ms\n","Speed: 3.4ms preprocess, 128.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 158.6ms\n","Speed: 3.2ms preprocess, 158.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 171.2ms\n","Speed: 3.3ms preprocess, 171.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 160.1ms\n","Speed: 3.9ms preprocess, 160.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 160.4ms\n","Speed: 3.7ms preprocess, 160.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 159.3ms\n","Speed: 3.3ms preprocess, 159.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 158.5ms\n","Speed: 3.7ms preprocess, 158.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 156.9ms\n","Speed: 5.3ms preprocess, 156.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 157.0ms\n","Speed: 3.3ms preprocess, 157.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 158.7ms\n","Speed: 5.9ms preprocess, 158.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 242.1ms\n","Speed: 3.3ms preprocess, 242.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 228.3ms\n","Speed: 3.8ms preprocess, 228.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 238.6ms\n","Speed: 3.5ms preprocess, 238.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 235.4ms\n","Speed: 3.3ms preprocess, 235.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 249.2ms\n","Speed: 4.5ms preprocess, 249.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 271.3ms\n","Speed: 3.6ms preprocess, 271.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 176.5ms\n","Speed: 3.2ms preprocess, 176.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 155.4ms\n","Speed: 7.0ms preprocess, 155.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 172.4ms\n","Speed: 3.1ms preprocess, 172.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 157.3ms\n","Speed: 4.7ms preprocess, 157.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 600.3ms\n","Speed: 21.6ms preprocess, 600.3ms inference, 6.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 668.2ms\n","Speed: 13.7ms preprocess, 668.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 216.4ms\n","Speed: 3.6ms preprocess, 216.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 309.3ms\n","Speed: 6.1ms preprocess, 309.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 1186.5ms\n","Speed: 14.2ms preprocess, 1186.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 236.9ms\n","Speed: 7.8ms preprocess, 236.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 228.8ms\n","Speed: 5.7ms preprocess, 228.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 247.5ms\n","Speed: 3.1ms preprocess, 247.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 188.2ms\n","Speed: 4.9ms preprocess, 188.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 154.3ms\n","Speed: 5.8ms preprocess, 154.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 158.3ms\n","Speed: 3.4ms preprocess, 158.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 155.6ms\n","Speed: 3.3ms preprocess, 155.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 155.9ms\n","Speed: 3.6ms preprocess, 155.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 160.0ms\n","Speed: 3.9ms preprocess, 160.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 156.6ms\n","Speed: 3.2ms preprocess, 156.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 154.6ms\n","Speed: 3.2ms preprocess, 154.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 154.1ms\n","Speed: 3.2ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 161.8ms\n","Speed: 5.0ms preprocess, 161.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 165.2ms\n","Speed: 3.9ms preprocess, 165.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 146.4ms\n","Speed: 12.3ms preprocess, 146.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 181.0ms\n","Speed: 3.1ms preprocess, 181.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 155.4ms\n","Speed: 3.3ms preprocess, 155.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 171.2ms\n","Speed: 5.2ms preprocess, 171.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 157.5ms\n","Speed: 4.1ms preprocess, 157.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 158.4ms\n","Speed: 3.3ms preprocess, 158.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.1ms\n","Speed: 3.1ms preprocess, 156.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.7ms\n","Speed: 3.3ms preprocess, 156.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 156.9ms\n","Speed: 3.1ms preprocess, 156.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 244.1ms\n","Speed: 3.2ms preprocess, 244.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 231.9ms\n","Speed: 7.5ms preprocess, 231.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 1 truck, 235.4ms\n","Speed: 3.3ms preprocess, 235.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 225.2ms\n","Speed: 6.7ms preprocess, 225.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 257.6ms\n","Speed: 3.2ms preprocess, 257.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 235.0ms\n","Speed: 6.3ms preprocess, 235.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 236.1ms\n","Speed: 6.3ms preprocess, 236.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 162.0ms\n","Speed: 4.2ms preprocess, 162.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 173.1ms\n","Speed: 5.9ms preprocess, 173.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 153.0ms\n","Speed: 3.2ms preprocess, 153.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 157.4ms\n","Speed: 3.2ms preprocess, 157.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 155.1ms\n","Speed: 3.2ms preprocess, 155.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 159.5ms\n","Speed: 3.7ms preprocess, 159.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 161.5ms\n","Speed: 3.4ms preprocess, 161.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 157.4ms\n","Speed: 3.3ms preprocess, 157.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 158.8ms\n","Speed: 3.5ms preprocess, 158.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 159.2ms\n","Speed: 3.2ms preprocess, 159.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 156.8ms\n","Speed: 3.5ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 155.0ms\n","Speed: 3.2ms preprocess, 155.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 159.7ms\n","Speed: 3.3ms preprocess, 159.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 165.4ms\n","Speed: 3.2ms preprocess, 165.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 152.0ms\n","Speed: 3.9ms preprocess, 152.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 159.9ms\n","Speed: 5.3ms preprocess, 159.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 152.7ms\n","Speed: 5.7ms preprocess, 152.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 152.6ms\n","Speed: 3.9ms preprocess, 152.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 154.3ms\n","Speed: 5.9ms preprocess, 154.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 159.7ms\n","Speed: 6.3ms preprocess, 159.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 153.6ms\n","Speed: 5.9ms preprocess, 153.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 261.5ms\n","Speed: 3.2ms preprocess, 261.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 249.4ms\n","Speed: 3.1ms preprocess, 249.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 220.7ms\n","Speed: 3.4ms preprocess, 220.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 243.2ms\n","Speed: 4.6ms preprocess, 243.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 205.9ms\n","Speed: 3.3ms preprocess, 205.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 236.9ms\n","Speed: 5.3ms preprocess, 236.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 150.3ms\n","Speed: 3.2ms preprocess, 150.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 1 traffic light, 158.6ms\n","Speed: 3.4ms preprocess, 158.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 2 traffic lights, 152.9ms\n","Speed: 3.4ms preprocess, 152.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 2 traffic lights, 158.7ms\n","Speed: 3.7ms preprocess, 158.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 traffic light, 155.4ms\n","Speed: 3.2ms preprocess, 155.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.7ms\n","Speed: 3.1ms preprocess, 156.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 153.8ms\n","Speed: 3.0ms preprocess, 153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 159.3ms\n","Speed: 3.1ms preprocess, 159.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 152.1ms\n","Speed: 3.1ms preprocess, 152.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 152.0ms\n","Speed: 3.2ms preprocess, 152.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 401.0ms\n","Speed: 6.5ms preprocess, 401.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 377.4ms\n","Speed: 3.2ms preprocess, 377.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 174.5ms\n","Speed: 3.1ms preprocess, 174.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 159.3ms\n","Speed: 3.3ms preprocess, 159.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 151.6ms\n","Speed: 3.0ms preprocess, 151.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 156.2ms\n","Speed: 3.2ms preprocess, 156.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 228.7ms\n","Speed: 3.1ms preprocess, 228.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 1 traffic light, 234.9ms\n","Speed: 9.0ms preprocess, 234.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 224.8ms\n","Speed: 7.7ms preprocess, 224.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 241.2ms\n","Speed: 7.1ms preprocess, 241.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 215.9ms\n","Speed: 3.3ms preprocess, 215.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 154.8ms\n","Speed: 3.2ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 155.0ms\n","Speed: 5.7ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 1 traffic light, 153.8ms\n","Speed: 3.2ms preprocess, 153.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 1 traffic light, 157.0ms\n","Speed: 3.0ms preprocess, 157.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 1 traffic light, 174.5ms\n","Speed: 4.0ms preprocess, 174.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 158.3ms\n","Speed: 3.1ms preprocess, 158.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 152.7ms\n","Speed: 3.1ms preprocess, 152.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 153.9ms\n","Speed: 4.6ms preprocess, 153.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 156.4ms\n","Speed: 3.4ms preprocess, 156.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 161.1ms\n","Speed: 3.7ms preprocess, 161.1ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 155.7ms\n","Speed: 4.1ms preprocess, 155.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 171.0ms\n","Speed: 5.4ms preprocess, 171.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 159.4ms\n","Speed: 3.2ms preprocess, 159.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 172.7ms\n","Speed: 3.4ms preprocess, 172.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 157.7ms\n","Speed: 3.8ms preprocess, 157.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 167.4ms\n","Speed: 3.6ms preprocess, 167.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 214.8ms\n","Speed: 3.1ms preprocess, 214.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 235.8ms\n","Speed: 9.4ms preprocess, 235.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 224.7ms\n","Speed: 3.3ms preprocess, 224.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 232.9ms\n","Speed: 4.2ms preprocess, 232.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 228.7ms\n","Speed: 4.3ms preprocess, 228.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 224.2ms\n","Speed: 7.9ms preprocess, 224.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 187.6ms\n","Speed: 4.8ms preprocess, 187.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.1ms\n","Speed: 4.8ms preprocess, 156.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 154.9ms\n","Speed: 3.1ms preprocess, 154.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 163.8ms\n","Speed: 3.1ms preprocess, 163.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 153.2ms\n","Speed: 4.0ms preprocess, 153.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 152.1ms\n","Speed: 3.2ms preprocess, 152.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 154.0ms\n","Speed: 7.2ms preprocess, 154.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 155.0ms\n","Speed: 4.0ms preprocess, 155.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 159.2ms\n","Speed: 3.4ms preprocess, 159.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 172.7ms\n","Speed: 3.2ms preprocess, 172.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 156.6ms\n","Speed: 3.4ms preprocess, 156.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 155.2ms\n","Speed: 5.9ms preprocess, 155.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 158.8ms\n","Speed: 5.5ms preprocess, 158.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 155.3ms\n","Speed: 3.3ms preprocess, 155.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 167.9ms\n","Speed: 3.2ms preprocess, 167.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 13 cars, 155.4ms\n","Speed: 4.7ms preprocess, 155.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 183.7ms\n","Speed: 3.4ms preprocess, 183.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 267.5ms\n","Speed: 3.3ms preprocess, 267.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 228.0ms\n","Speed: 7.3ms preprocess, 228.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 243.1ms\n","Speed: 3.6ms preprocess, 243.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 228.7ms\n","Speed: 5.2ms preprocess, 228.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 248.8ms\n","Speed: 7.4ms preprocess, 248.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 174.0ms\n","Speed: 5.8ms preprocess, 174.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 155.8ms\n","Speed: 3.4ms preprocess, 155.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 156.2ms\n","Speed: 6.8ms preprocess, 156.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 156.5ms\n","Speed: 3.9ms preprocess, 156.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 157.0ms\n","Speed: 3.3ms preprocess, 157.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 156.2ms\n","Speed: 3.5ms preprocess, 156.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 160.1ms\n","Speed: 5.7ms preprocess, 160.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 172.7ms\n","Speed: 3.3ms preprocess, 172.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 157.9ms\n","Speed: 3.9ms preprocess, 157.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 154.7ms\n","Speed: 4.2ms preprocess, 154.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 173.8ms\n","Speed: 3.2ms preprocess, 173.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 154.3ms\n","Speed: 5.4ms preprocess, 154.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 168.1ms\n","Speed: 3.3ms preprocess, 168.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 156.3ms\n","Speed: 3.1ms preprocess, 156.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 154.5ms\n","Speed: 4.7ms preprocess, 154.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 169.0ms\n","Speed: 3.1ms preprocess, 169.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 153.5ms\n","Speed: 4.4ms preprocess, 153.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 248.0ms\n","Speed: 3.4ms preprocess, 248.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 1 traffic light, 222.4ms\n","Speed: 11.0ms preprocess, 222.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 241.0ms\n","Speed: 11.3ms preprocess, 241.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 2 trucks, 1 traffic light, 225.5ms\n","Speed: 3.1ms preprocess, 225.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 3 trucks, 1 traffic light, 216.4ms\n","Speed: 3.3ms preprocess, 216.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 3 trucks, 1 traffic light, 162.1ms\n","Speed: 4.5ms preprocess, 162.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 3 trucks, 1 traffic light, 163.8ms\n","Speed: 4.5ms preprocess, 163.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 3 trucks, 1 traffic light, 156.7ms\n","Speed: 3.3ms preprocess, 156.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 3 trucks, 1 traffic light, 153.4ms\n","Speed: 3.3ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 3 trucks, 1 traffic light, 168.3ms\n","Speed: 3.9ms preprocess, 168.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 3 trucks, 155.6ms\n","Speed: 4.2ms preprocess, 155.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 3 trucks, 1 traffic light, 172.7ms\n","Speed: 3.6ms preprocess, 172.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 3 trucks, 159.4ms\n","Speed: 3.2ms preprocess, 159.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 3 trucks, 157.6ms\n","Speed: 4.8ms preprocess, 157.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 158.4ms\n","Speed: 3.2ms preprocess, 158.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 153.7ms\n","Speed: 3.2ms preprocess, 153.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 2 trucks, 157.9ms\n","Speed: 4.0ms preprocess, 157.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 2 trucks, 158.5ms\n","Speed: 3.2ms preprocess, 158.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 155.8ms\n","Speed: 6.1ms preprocess, 155.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 2 trucks, 210.7ms\n","Speed: 4.2ms preprocess, 210.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 1 traffic light, 222.6ms\n","Speed: 8.5ms preprocess, 222.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 1 traffic light, 241.3ms\n","Speed: 6.1ms preprocess, 241.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 285.7ms\n","Speed: 8.4ms preprocess, 285.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 1 traffic light, 224.3ms\n","Speed: 6.3ms preprocess, 224.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 155.5ms\n","Speed: 3.2ms preprocess, 155.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 158.2ms\n","Speed: 3.2ms preprocess, 158.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 154.4ms\n","Speed: 5.7ms preprocess, 154.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 155.4ms\n","Speed: 3.1ms preprocess, 155.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 155.1ms\n","Speed: 5.3ms preprocess, 155.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 157.5ms\n","Speed: 3.9ms preprocess, 157.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 154.1ms\n","Speed: 3.1ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 traffic light, 160.5ms\n","Speed: 3.2ms preprocess, 160.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 155.4ms\n","Speed: 3.1ms preprocess, 155.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 152.2ms\n","Speed: 6.2ms preprocess, 152.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 154.0ms\n","Speed: 3.2ms preprocess, 154.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 2 trucks, 157.0ms\n","Speed: 3.5ms preprocess, 157.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 157.0ms\n","Speed: 3.3ms preprocess, 157.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 163.5ms\n","Speed: 3.4ms preprocess, 163.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 166.0ms\n","Speed: 4.0ms preprocess, 166.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 162.0ms\n","Speed: 3.5ms preprocess, 162.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 156.7ms\n","Speed: 3.2ms preprocess, 156.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 239.9ms\n","Speed: 3.3ms preprocess, 239.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 235.6ms\n","Speed: 3.2ms preprocess, 235.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 226.9ms\n","Speed: 6.5ms preprocess, 226.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 224.9ms\n","Speed: 3.2ms preprocess, 224.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 227.6ms\n","Speed: 5.0ms preprocess, 227.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 153.5ms\n","Speed: 3.3ms preprocess, 153.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 160.5ms\n","Speed: 4.3ms preprocess, 160.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 155.4ms\n","Speed: 3.4ms preprocess, 155.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 159.8ms\n","Speed: 6.5ms preprocess, 159.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 1 traffic light, 177.6ms\n","Speed: 3.7ms preprocess, 177.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 157.6ms\n","Speed: 3.3ms preprocess, 157.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 2 trucks, 1 traffic light, 160.1ms\n","Speed: 4.0ms preprocess, 160.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 1 traffic light, 156.4ms\n","Speed: 3.3ms preprocess, 156.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 156.6ms\n","Speed: 3.3ms preprocess, 156.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 160.9ms\n","Speed: 3.2ms preprocess, 160.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 154.4ms\n","Speed: 3.3ms preprocess, 154.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 162.6ms\n","Speed: 5.0ms preprocess, 162.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 157.0ms\n","Speed: 3.4ms preprocess, 157.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 154.3ms\n","Speed: 5.6ms preprocess, 154.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 154.8ms\n","Speed: 3.5ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 158.7ms\n","Speed: 3.2ms preprocess, 158.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 170.7ms\n","Speed: 4.0ms preprocess, 170.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 232.1ms\n","Speed: 4.0ms preprocess, 232.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 240.4ms\n","Speed: 3.5ms preprocess, 240.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 2 traffic lights, 247.8ms\n","Speed: 3.3ms preprocess, 247.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 trucks, 1 traffic light, 219.5ms\n","Speed: 7.8ms preprocess, 219.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 1 traffic light, 249.0ms\n","Speed: 7.2ms preprocess, 249.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 1 traffic light, 154.1ms\n","Speed: 3.1ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 156.8ms\n","Speed: 3.1ms preprocess, 156.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 152.9ms\n","Speed: 5.2ms preprocess, 152.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 1 traffic light, 171.9ms\n","Speed: 5.3ms preprocess, 171.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 1 traffic light, 156.6ms\n","Speed: 3.3ms preprocess, 156.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 1 traffic light, 155.7ms\n","Speed: 3.2ms preprocess, 155.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 152.9ms\n","Speed: 7.0ms preprocess, 152.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 traffic lights, 173.3ms\n","Speed: 3.3ms preprocess, 173.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 2 traffic lights, 152.6ms\n","Speed: 3.5ms preprocess, 152.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 1 traffic light, 159.1ms\n","Speed: 3.2ms preprocess, 159.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 1 traffic light, 156.2ms\n","Speed: 3.5ms preprocess, 156.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 traffic lights, 153.8ms\n","Speed: 3.3ms preprocess, 153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 157.6ms\n","Speed: 3.7ms preprocess, 157.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 traffic light, 159.0ms\n","Speed: 3.3ms preprocess, 159.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 3 traffic lights, 154.8ms\n","Speed: 6.3ms preprocess, 154.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 traffic lights, 153.9ms\n","Speed: 3.2ms preprocess, 153.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.0ms\n","Speed: 6.7ms preprocess, 156.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 154.9ms\n","Speed: 3.1ms preprocess, 154.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 228.0ms\n","Speed: 3.3ms preprocess, 228.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 223.1ms\n","Speed: 3.2ms preprocess, 223.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 250.9ms\n","Speed: 3.3ms preprocess, 250.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 228.0ms\n","Speed: 4.1ms preprocess, 228.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 traffic lights, 251.9ms\n","Speed: 3.1ms preprocess, 251.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 183.7ms\n","Speed: 3.3ms preprocess, 183.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 2 traffic lights, 157.4ms\n","Speed: 3.1ms preprocess, 157.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 2 traffic lights, 161.0ms\n","Speed: 3.3ms preprocess, 161.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 156.4ms\n","Speed: 3.2ms preprocess, 156.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 traffic lights, 168.6ms\n","Speed: 4.1ms preprocess, 168.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 155.5ms\n","Speed: 3.6ms preprocess, 155.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 163.6ms\n","Speed: 5.8ms preprocess, 163.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.0ms\n","Speed: 3.6ms preprocess, 156.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 169.4ms\n","Speed: 3.1ms preprocess, 169.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 154.1ms\n","Speed: 6.0ms preprocess, 154.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 153.1ms\n","Speed: 3.1ms preprocess, 153.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 155.3ms\n","Speed: 3.5ms preprocess, 155.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 156.1ms\n","Speed: 7.8ms preprocess, 156.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 151.0ms\n","Speed: 3.3ms preprocess, 151.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 161.9ms\n","Speed: 3.1ms preprocess, 161.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 145.0ms\n","Speed: 5.5ms preprocess, 145.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 167.6ms\n","Speed: 3.1ms preprocess, 167.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 152.4ms\n","Speed: 6.3ms preprocess, 152.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 155.0ms\n","Speed: 3.2ms preprocess, 155.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 161.2ms\n","Speed: 5.3ms preprocess, 161.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 233.9ms\n","Speed: 3.2ms preprocess, 233.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 236.3ms\n","Speed: 3.2ms preprocess, 236.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 238.6ms\n","Speed: 3.3ms preprocess, 238.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 1 truck, 238.2ms\n","Speed: 3.2ms preprocess, 238.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 244.0ms\n","Speed: 5.2ms preprocess, 244.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 241.8ms\n","Speed: 5.5ms preprocess, 241.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 1 truck, 159.4ms\n","Speed: 8.3ms preprocess, 159.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 trucks, 179.3ms\n","Speed: 3.3ms preprocess, 179.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 trucks, 158.2ms\n","Speed: 3.1ms preprocess, 158.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 161.9ms\n","Speed: 3.3ms preprocess, 161.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 trucks, 159.8ms\n","Speed: 3.2ms preprocess, 159.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 2 trucks, 168.0ms\n","Speed: 3.5ms preprocess, 168.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 2 trucks, 1 traffic light, 159.6ms\n","Speed: 3.2ms preprocess, 159.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 2 trucks, 172.2ms\n","Speed: 7.6ms preprocess, 172.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 1 traffic light, 174.0ms\n","Speed: 5.7ms preprocess, 174.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 1 traffic light, 170.8ms\n","Speed: 3.2ms preprocess, 170.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 2 trucks, 1 traffic light, 153.0ms\n","Speed: 9.1ms preprocess, 153.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 2 trucks, 159.9ms\n","Speed: 3.8ms preprocess, 159.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 154.7ms\n","Speed: 6.4ms preprocess, 154.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 161.7ms\n","Speed: 5.0ms preprocess, 161.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 154.7ms\n","Speed: 4.3ms preprocess, 154.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 171.9ms\n","Speed: 3.9ms preprocess, 171.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 6 cars, 2 trucks, 1 traffic light, 158.4ms\n","Speed: 3.2ms preprocess, 158.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 2 traffic lights, 160.3ms\n","Speed: 3.4ms preprocess, 160.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 157.8ms\n","Speed: 3.4ms preprocess, 157.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 244.6ms\n","Speed: 3.2ms preprocess, 244.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 5 cars, 2 trucks, 1 traffic light, 224.8ms\n","Speed: 5.9ms preprocess, 224.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 7 cars, 2 trucks, 1 traffic light, 221.7ms\n","Speed: 3.3ms preprocess, 221.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 249.8ms\n","Speed: 5.1ms preprocess, 249.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 trucks, 1 traffic light, 241.5ms\n","Speed: 3.1ms preprocess, 241.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 2 trucks, 2 traffic lights, 216.7ms\n","Speed: 3.2ms preprocess, 216.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 9 cars, 1 truck, 2 traffic lights, 155.3ms\n","Speed: 3.2ms preprocess, 155.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 2 traffic lights, 163.9ms\n","Speed: 5.8ms preprocess, 163.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 truck, 1 traffic light, 156.0ms\n","Speed: 6.0ms preprocess, 156.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 177.1ms\n","Speed: 3.2ms preprocess, 177.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 154.3ms\n","Speed: 3.1ms preprocess, 154.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 1 traffic light, 182.7ms\n","Speed: 3.1ms preprocess, 182.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 156.1ms\n","Speed: 6.6ms preprocess, 156.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 8 cars, 2 traffic lights, 158.0ms\n","Speed: 4.4ms preprocess, 158.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n"]}],"source":["import cv2\n","import numpy as np\n","import csv\n","from ultralytics import YOLO\n","from deep_sort_realtime.deepsort_tracker import DeepSort\n","from collections import defaultdict\n","\n","# Функция проверки пересечения двух отрезков\n","def intersect(p1, p2, line_p1, line_p2):\n","    def ccw(A, B, C):\n","        return (C[1] - A[1]) * (B[0] - A[0]) > (B[1] - A[1]) * (C[0] - A[0])\n","\n","    return ccw(p1, line_p1, line_p2) != ccw(p2, line_p1, line_p2) and \\\n","           ccw(p1, p2, line_p1) != ccw(p1, p2, line_p2)\n","\n","# Путь к видео\n","video_input = \"/content/drive/MyDrive/3 курс/2 семестр/Машинное зрение/15/car_jaaam.mp4\"\n","output_video = \"counted_objects_output.mp4\"\n","\n","# Инициализация модели и трекера\n","model = YOLO(\"yolov8n.pt\")\n","tracker = DeepSort(max_age=30)\n","\n","# Словари и списки для хранения данных\n","object_positions = {}  # Хранит последние позиции треков\n","counts_left = defaultdict(int)  # Подсчет пересечений слева направо\n","counts_right = defaultdict(int)  # Подсчет пересечений справа налево\n","metadata_list = []  # Метаданные для CSV\n","\n","# Открытие видеопотока\n","cap = cv2.VideoCapture(video_input)\n","if not cap.isOpened():\n","    print(f\"Ошибка: Не удалось открыть видео {video_input}\")\n","    exit()\n","\n","# Параметры видео\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","frame_rate = cap.get(cv2.CAP_PROP_FPS)\n","\n","# Проверка корректности параметров\n","if frame_width == 0 or frame_height == 0:\n","    print(\"Ошибка: Неверные размеры видео\")\n","    cap.release()\n","    exit()\n","\n","# Определение вертикальной линии по центру\n","center_line_x = frame_width // 2\n","line_start = (center_line_x, 0)\n","line_end = (center_line_x, frame_height)\n","\n","# Настройка выходного видео\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(output_video, fourcc, frame_rate, (frame_width, frame_height))\n","\n","current_frame = 0\n","while True:\n","    success, frame = cap.read()\n","    if not success:\n","        print(f\"Инфо: Конец видео или ошибка на кадре {current_frame}\")\n","        break\n","\n","    # Детекция объектов с помощью YOLOv8\n","    results = model(frame)[0]\n","    detected_objects = []\n","    for detection in results.boxes.data.tolist():\n","        x1, y1, x2, y2, confidence, class_id = detection\n","        class_label = model.names[int(class_id)]\n","        detected_objects.append(([x1, y1, x2 - x1, y2 - y1], confidence, class_label))\n","\n","    # Обновление треков\n","    tracked_objects = tracker.update_tracks(detected_objects, frame=frame)\n","\n","    # Обработка треков\n","    for track in tracked_objects:\n","        if not track.is_confirmed():\n","            continue\n","\n","        track_id = track.track_id\n","        bbox = track.to_ltrb()\n","        x1, y1, x2, y2 = map(int, bbox)\n","        center_x = (x1 + x2) // 2\n","        center_y = (y1 + y2) // 2\n","        class_label = track.get_det_class()\n","\n","        # Сохранение метаданных\n","        metadata_list.append([current_frame, track_id, class_label, center_x, center_y])\n","\n","        # Обновление позиций трека\n","        if track_id not in object_positions:\n","            object_positions[track_id] = []\n","        object_positions[track_id].append((center_x, center_y))\n","\n","        # Проверка пересечения вертикальной линии\n","        if len(object_positions[track_id]) > 2:\n","            object_positions[track_id] = object_positions[track_id][-2:]\n","            prev_pos, curr_pos = object_positions[track_id]\n","            if intersect(prev_pos, curr_pos, line_start, line_end):\n","                if prev_pos[0] > curr_pos[0]:  # Справа налево\n","                    counts_left[class_label] += 1\n","                else:  # Слева направо\n","                    counts_right[class_label] += 1\n","                object_positions[track_id] = [(0, 0)]  # Сброс после пересечения\n","\n","        # Отрисовка bounding box и идентификатора\n","        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","        cv2.putText(frame, f\"{class_label} ID:{track_id}\", (x1, y1 - 10),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","    # Отрисовка счетчиков\n","    y_offset = 30\n","    all_classes = set(counts_left.keys()) | set(counts_right.keys())\n","    for cls in sorted(all_classes):\n","        text = f\"{cls}: Left: {counts_left[cls]} Right: {counts_right[cls]}\"\n","        cv2.putText(frame, text, (30, y_offset), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)\n","        y_offset += 25\n","\n","    # Отрисовка вертикальной линии\n","    cv2.line(frame, line_start, line_end, (0, 0, 255), 2)\n","\n","    # Сохранение кадра\n","    out.write(frame)\n","    current_frame += 1\n","\n","# Освобождение ресурсов\n","cap.release()\n","out.release()\n","\n","# Сохранение метаданных в CSV\n","with open(\"object_tracking_data.csv\", \"w\", newline=\"\") as csvfile:\n","    writer = csv.writer(csvfile)\n","    writer.writerow([\"Frame\", \"ObjectID\", \"Class\", \"CenterX\", \"CenterY\"])\n","    writer.writerows(metadata_list)\n","\n","# Вывод итоговой статистики\n","print(\"Итоговая статистика:\")\n","print(\"Слева направо:\", dict(counts_right) if counts_right else \"Нет пересечений\")\n","print(\"Справа налево:\", dict(counts_left) if counts_left else \"Нет пересечений\")"]},{"cell_type":"code","source":["from google.colab import drive\n","from IPython.display import Video\n","import cv2\n","import os\n","\n","# Монтируем Google Drive\n","drive.mount('/content/drive')\n","\n","# Путь к видео\n","video_path = '/content/drive/MyDrive/3 курс/2 семестр /Машинное зрение /15/counted_output.avi'\n","\n","# Проверка существования файла\n","if not os.path.exists(video_path):\n","    print(f\"Ошибка: Файл {video_path} не существует\")\n","else:\n","    # Проверка возможности открытия видео\n","    cap = cv2.VideoCapture(video_path)\n","    if not cap.isOpened():\n","        print(f\"Ошибка: Не удалось открыть видео {video_path}. Попробуем перекодировать...\")\n","        !apt-get install ffmpeg\n","        !ffmpeg -i \"{video_path}\" -c:v libx264 -c:a aac /content/converted_video.mp4\n","        video_path = '/content/converted_video.mp4'\n","    else:\n","        # Проверка параметров видео\n","        fps = cap.get(cv2.CAP_PROP_FPS)\n","        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","        duration = frame_count / fps\n","        print(f'FPS: {fps}, Frames: {frame_count}, Duration: {duration:.2f} seconds')\n","        cap.release()\n","\n","        # Конвертация, если не соответствует требованиям (10 секунд, 100–150 кадров)\n","        if duration > 13 or fps > 30:\n","            print(\"Конвертируем видео до 10 секунд и 10 FPS...\")\n","            !apt-get install ffmpeg\n","            !ffmpeg -i \"{video_path}\" -t 10 -r 30 /content/output_10fps.mp4\n","            video_path = '/content/output_10fps.mp4'\n","\n","# Отображение видео\n","Video(video_path, embed=True, width=640, height=360, html_attributes=\"controls autoplay\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1dPu7HYJvE1dL8dUgbyynnz7IOBxbF4Ym"},"id":"GWyIrwHtOAvh","executionInfo":{"status":"ok","timestamp":1748625916193,"user_tz":-180,"elapsed":32972,"user":{"displayName":"Nikolay Bukin","userId":"12801653507391334847"}},"outputId":"e532bc35-e9fb-4906-fd9d-a99876d86b73"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"yy8UhJP6ZAVH"},"source":["# Задача 2"]},{"cell_type":"markdown","metadata":{"id":"7PP916_8Y_V2"},"source":["На основе алгоритма DeepSORT реализуйте сохранение метаданных трекинга в файл (id, координаты, класс)"]},{"cell_type":"markdown","metadata":{"id":"6djywUNXHf5U"},"source":["#Задача 3"]},{"cell_type":"markdown","metadata":{"id":"M7k9bv2gHlFZ"},"source":["Выведите время жизни каждого трека. То есть отслеживаете отдельный id и считаете его время жизни."]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}