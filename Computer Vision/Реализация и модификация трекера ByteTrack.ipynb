{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# ByteTrack"],"metadata":{"id":"CUuhnjbDt8Rn"}},{"cell_type":"markdown","source":["ByteTrack — это современный алгоритм многопотокового трекинга объектов (Multi-Object Tracking, MOT), который эффективно связывает объекты между кадрами видео, даже если они временно пропадают из-за перекрытий или ложных срабатываний.\n","\n","Он был представлен в 2021 году как улучшение классического SORT (Simple Online and Realtime Tracking) и DeepSORT, и особенно хорошо работает в сложных сценах с высокой плотностью объектов."],"metadata":{"id":"n_YV1fx33z76"}},{"cell_type":"markdown","source":["Особенности ByteTrack:\n","\n","1. Использование \"слабых\" детекций\n","\n","* В отличие от SORT/DeepSORT, которые отфильтровывают детекции с низким confidence (например, < 0.5), ByteTrack сохраняет их для сопоставления с \"потерянными\" треками.\n","\n","* Это помогает избежать \"пропажи\" объектов при временных ложных негативах детектора.\n","\n","2. Двухэтапное сопоставление\n","\n","* Первая стадия: Сопоставление треков с \"надежными\" детекциями (высокий confidence).\n","\n","* Вторая стадия: Сопоставление оставшихся треков с \"слабыми\" детекциями (низкий confidence).\n","\n","3. Отслеживание по bounding box (без ReID)\n","\n","ByteTrack полагается на IoU (Intersection over Union) и движение объектов (через Kalman Filter), но не использует re-identification (ReID) модели, что делает его быстрее DeepSORT."],"metadata":{"id":"2lKCXsNR3MXR"}},{"cell_type":"markdown","source":["## Реализация упрощенного трекера ByteTrack"],"metadata":{"id":"phokSBBXt-SV"}},{"cell_type":"code","source":["!pip install numpy opencv-python Pillow onemetric\n","!pip install git+https://github.com/ifzhang/ByteTrack.git --no-deps"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"030ruyx9YfmR","outputId":"8c2036b6-5ac0-4ed9-b6e8-ddf0fd8b52e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n","Requirement already satisfied: onemetric in /usr/local/lib/python3.11/dist-packages (0.1.2)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (from onemetric) (0.13.2)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from onemetric) (3.10.0)\n","Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from onemetric) (0.6.7)\n","Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->onemetric) (3.26.1)\n","Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->onemetric) (0.9.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->onemetric) (2.9.0.post0)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn->onemetric) (2.2.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->onemetric) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn->onemetric) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->onemetric) (1.17.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->onemetric) (1.1.0)\n","Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->onemetric) (4.13.2)\n","Collecting git+https://github.com/ifzhang/ByteTrack.git\n","  Cloning https://github.com/ifzhang/ByteTrack.git to /tmp/pip-req-build-ia5t5xmk\n","  Running command git clone --filter=blob:none --quiet https://github.com/ifzhang/ByteTrack.git /tmp/pip-req-build-ia5t5xmk\n","  Resolved https://github.com/ifzhang/ByteTrack.git to commit d1bf0191adff59bc8fcfeaa0b33d3d1642552a99\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["!pip install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pZn-In-Cm6ZV","outputId":"3edd8e73-f07d-48c8-87cb-aab7e405387c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: ultralytics in /usr/local/lib/python3.11/dist-packages (8.3.151)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n","Requirement already satisfied: ultralytics-thop>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.14)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.58.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from datetime import datetime\n","from ultralytics import YOLO\n","\n","# Своя реализация IoU на NumPy\n","def iou_batch(bboxes1, bboxes2):\n","    x11, y11, x12, y12 = np.split(bboxes1, 4, axis=1)\n","    x21, y21, x22, y22 = np.split(bboxes2, 4, axis=1)\n","\n","    xA = np.maximum(x11, x21.T)\n","    yA = np.maximum(y11, y21.T)\n","    xB = np.minimum(x12, x22.T)\n","    yB = np.minimum(y12, y22.T)\n","\n","    interArea = np.maximum(0, xB - xA) * np.maximum(0, yB - yA)\n","    boxAArea = (x12 - x11) * (y12 - y11)\n","    boxBArea = (x22 - x21) * (y22 - y21)\n","\n","    iou = interArea / (boxAArea + boxBArea.T - interArea)\n","    return iou\n","\n","class SimpleByteTracker:\n","    def __init__(self, track_thresh=0.5, match_thresh=0.8, max_misses=5):\n","        self.track_thresh = track_thresh\n","        self.match_thresh = match_thresh\n","        self.max_misses = max_misses  # Макс. число кадров без обновления\n","        self.tracks = []\n","        self.next_id = 1\n","\n","    def update(self, detections, img_size):\n","        valid_dets = [d for d in detections if d[4] >= self.track_thresh]\n","        matched = set()\n","        matched_tracks = set()\n","\n","        # Увеличиваем счётчик пропусков для всех треков\n","        for track in self.tracks:\n","            track['misses'] += 1\n","\n","        if self.tracks and valid_dets:\n","            track_boxes = np.array([t['bbox'] for t in self.tracks])\n","            det_boxes = np.array([d[:4] for d in valid_dets])\n","\n","            iou_matrix = iou_batch(track_boxes, det_boxes)\n","\n","            for i, track in enumerate(self.tracks):\n","                best_match = np.argmax(iou_matrix[i])\n","                if iou_matrix[i, best_match] > self.match_thresh:\n","                    track['bbox'] = valid_dets[best_match][:4]\n","                    track['misses'] = 0  # Сброс счётчика\n","                    matched.add(best_match)\n","                    matched_tracks.add(i)\n","\n","        # Удаляем треки, которые долго не обновлялись\n","        self.tracks = [\n","            t for t in self.tracks\n","            if t['misses'] <= self.max_misses\n","        ]\n","\n","        # Добавляем новые треки\n","        for i, det in enumerate(valid_dets):\n","            if i not in matched:\n","                self.tracks.append({\n","                    'id': self.next_id,\n","                    'bbox': det[:4],\n","                    'score': det[4],\n","                    'misses': 0  # Инициализация счётчика\n","                })\n","                self.next_id += 1\n","\n","        return self.tracks"],"metadata":{"id":"z2R158p9aCpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab.patches import cv2_imshow"],"metadata":{"id":"XsQBPdp1pfhv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Инициализация модели YOLOv8\n","model = YOLO(\"yolov8n.pt\")  # Загрузка nano-модели (можно yolov8s.pt, yolov8m.pt и т.д.)\n","\n","# Инициализация видео\n","cap = cv2.VideoCapture('/content/drive/MyDrive/datasets/cv/pedestrian.mp4')  # Или путь к видеофайлу\n","\n","# Настройки выходного видео\n","frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","\n","# Создаем имя файла с текущей датой/временем\n","output_filename = f\"tracking_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4\"\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","out = cv2.VideoWriter(output_filename, fourcc, fps, (frame_width, frame_height))\n","\n","tracker = SimpleByteTracker()\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # Детекция объектов (можно настроить confidence threshold)\n","    results = model(frame, conf=0.5)  # conf - порог уверенности\n","\n","    # Преобразуем результаты в формат [x1, y1, x2, y2, conf, class_id]\n","    detections = []\n","    for result in results:\n","        boxes = result.boxes.xyxy.cpu().numpy()  # bounding boxes\n","        confs = result.boxes.conf.cpu().numpy()  # confidence scores\n","        class_ids = result.boxes.cls.cpu().numpy()  # class IDs\n","\n","        for box, conf, cls_id in zip(boxes, confs, class_ids):\n","            x1, y1, x2, y2 = box\n","            detections.append([x1, y1, x2, y2, conf, cls_id])\n","\n","\n","    # Обновление трекера\n","    tracks = tracker.update(detections, (frame.shape[1], frame.shape[0]))\n","\n","    # Рисуем результат на кадре\n","    for track in tracks:\n","        x1, y1, x2, y2 = map(int, track['bbox'])\n","        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n","        cv2.putText(frame, f\"ID: {track['id']}\", (x1, y1-10),\n","                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n","\n","    # Записываем кадр в видео\n","    out.write(frame)\n","\n","# Освобождаем ресурсы\n","cap.release()\n","out.release()\n","# cv2.destroyAllWindows()\n","\n","print(f\"Видео сохранено как: {output_filename}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gjA04ddHaHCg","outputId":"d27672d4-9995-4f88-ce46-a104b5c894eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 2 persons, 10 cars, 9.7ms\n","Speed: 2.1ms preprocess, 9.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 10 cars, 8.5ms\n","Speed: 2.2ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 11 cars, 6.9ms\n","Speed: 2.1ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 13 cars, 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 10.4ms\n","Speed: 2.1ms preprocess, 10.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.4ms\n","Speed: 2.0ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 10.0ms\n","Speed: 2.1ms preprocess, 10.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.4ms\n","Speed: 2.0ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 7.1ms\n","Speed: 2.1ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.2ms\n","Speed: 2.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 6.9ms\n","Speed: 2.0ms preprocess, 6.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.3ms\n","Speed: 2.0ms preprocess, 7.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 7.5ms\n","Speed: 2.0ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 6.8ms\n","Speed: 1.8ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 7.2ms\n","Speed: 3.2ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.7ms\n","Speed: 1.8ms preprocess, 7.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 9.0ms\n","Speed: 2.2ms preprocess, 9.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 12 cars, 7.9ms\n","Speed: 2.9ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 8.4ms\n","Speed: 2.2ms preprocess, 8.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 6.9ms\n","Speed: 2.8ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 7.9ms\n","Speed: 2.1ms preprocess, 7.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 6.9ms\n","Speed: 2.6ms preprocess, 6.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 6.8ms\n","Speed: 2.1ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 8.3ms\n","Speed: 2.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 12 cars, 6.6ms\n","Speed: 2.1ms preprocess, 6.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 12 cars, 8.6ms\n","Speed: 2.1ms preprocess, 8.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 8.3ms\n","Speed: 2.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 8.5ms\n","Speed: 2.8ms preprocess, 8.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 6.8ms\n","Speed: 1.6ms preprocess, 6.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 7.7ms\n","Speed: 2.7ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 8.8ms\n","Speed: 2.3ms preprocess, 8.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 12.8ms\n","Speed: 2.3ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 7.0ms\n","Speed: 2.1ms preprocess, 7.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 8.2ms\n","Speed: 2.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 6.7ms\n","Speed: 2.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8 cars, 1 truck, 7.4ms\n","Speed: 2.2ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 7.3ms\n","Speed: 2.3ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 1 bus, 6.7ms\n","Speed: 2.1ms preprocess, 6.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 bus, 8.8ms\n","Speed: 2.1ms preprocess, 8.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8 cars, 1 bus, 7.3ms\n","Speed: 2.1ms preprocess, 7.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 7.2ms\n","Speed: 2.3ms preprocess, 7.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 bus, 6.6ms\n","Speed: 2.0ms preprocess, 6.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 bus, 9.3ms\n","Speed: 2.0ms preprocess, 9.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 bus, 7.5ms\n","Speed: 2.4ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 bus, 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 bus, 8.0ms\n","Speed: 2.3ms preprocess, 8.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 1 bus, 6.9ms\n","Speed: 2.3ms preprocess, 6.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 8 cars, 1 bus, 8.9ms\n","Speed: 2.2ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 1 bus, 8.2ms\n","Speed: 2.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 1 bus, 9.4ms\n","Speed: 2.1ms preprocess, 9.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 bus, 7.5ms\n","Speed: 2.3ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 bus, 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 8.6ms\n","Speed: 2.2ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 1 truck, 8.3ms\n","Speed: 2.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 4 cars, 1 truck, 7.4ms\n","Speed: 2.3ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 truck, 7.4ms\n","Speed: 2.1ms preprocess, 7.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 truck, 9.1ms\n","Speed: 2.2ms preprocess, 9.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 truck, 7.1ms\n","Speed: 1.7ms preprocess, 7.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 truck, 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 8.2ms\n","Speed: 2.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 7.7ms\n","Speed: 2.2ms preprocess, 7.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 truck, 8.6ms\n","Speed: 2.1ms preprocess, 8.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 6.8ms\n","Speed: 1.9ms preprocess, 6.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 8.2ms\n","Speed: 2.1ms preprocess, 8.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 7.8ms\n","Speed: 2.1ms preprocess, 7.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 truck, 7.6ms\n","Speed: 2.7ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 truck, 8.3ms\n","Speed: 2.1ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 truck, 7.4ms\n","Speed: 2.7ms preprocess, 7.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 truck, 8.9ms\n","Speed: 2.1ms preprocess, 8.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 truck, 9.8ms\n","Speed: 2.1ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 12.9ms\n","Speed: 2.0ms preprocess, 12.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 5 cars, 1 truck, 7.6ms\n","Speed: 2.2ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 6 cars, 1 truck, 7.6ms\n","Speed: 1.9ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 7.9ms\n","Speed: 1.9ms preprocess, 7.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 7.5ms\n","Speed: 2.0ms preprocess, 7.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 4 cars, 1 truck, 7.6ms\n","Speed: 2.0ms preprocess, 7.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 8.3ms\n","Speed: 2.0ms preprocess, 8.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 8.8ms\n","Speed: 2.5ms preprocess, 8.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 4 cars, 1 truck, 35.3ms\n","Speed: 14.2ms preprocess, 35.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 4 cars, 1 truck, 12.6ms\n","Speed: 2.6ms preprocess, 12.6ms inference, 9.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 4 cars, 1 truck, 11.2ms\n","Speed: 2.4ms preprocess, 11.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 4 cars, 1 truck, 10.8ms\n","Speed: 2.1ms preprocess, 10.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 9.6ms\n","Speed: 2.8ms preprocess, 9.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 19.4ms\n","Speed: 2.3ms preprocess, 19.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 11.1ms\n","Speed: 2.5ms preprocess, 11.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 29.0ms\n","Speed: 2.3ms preprocess, 29.0ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 1 truck, 13.7ms\n","Speed: 2.5ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 1 truck, 13.1ms\n","Speed: 2.7ms preprocess, 13.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 1 truck, 18.7ms\n","Speed: 2.2ms preprocess, 18.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 1 truck, 26.2ms\n","Speed: 7.2ms preprocess, 26.2ms inference, 8.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 7 cars, 42.1ms\n","Speed: 7.5ms preprocess, 42.1ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 22.1ms\n","Speed: 2.4ms preprocess, 22.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 10.6ms\n","Speed: 2.3ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 10.4ms\n","Speed: 2.4ms preprocess, 10.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 17.9ms\n","Speed: 3.8ms preprocess, 17.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 13.9ms\n","Speed: 2.2ms preprocess, 13.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 11.1ms\n","Speed: 2.2ms preprocess, 11.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 persons, 5 cars, 1 truck, 15.0ms\n","Speed: 2.3ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 5 cars, 1 truck, 9.1ms\n","Speed: 2.1ms preprocess, 9.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 persons, 7 cars, 1 truck, 14.1ms\n","Speed: 4.7ms preprocess, 14.1ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 3 persons, 6 cars, 1 truck, 9.8ms\n","Speed: 2.9ms preprocess, 9.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 13.2ms\n","Speed: 3.9ms preprocess, 13.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 10.9ms\n","Speed: 2.2ms preprocess, 10.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 18.5ms\n","Speed: 2.1ms preprocess, 18.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 6 cars, 1 truck, 11.2ms\n","Speed: 2.3ms preprocess, 11.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 1 truck, 14.1ms\n","Speed: 2.3ms preprocess, 14.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 1 truck, 10.6ms\n","Speed: 2.4ms preprocess, 10.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 1 truck, 15.6ms\n","Speed: 2.2ms preprocess, 15.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 7 cars, 1 truck, 26.8ms\n","Speed: 2.1ms preprocess, 26.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 9 cars, 1 truck, 10.3ms\n","Speed: 2.2ms preprocess, 10.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 8 cars, 1 truck, 10.3ms\n","Speed: 2.2ms preprocess, 10.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 9 cars, 1 truck, 9.9ms\n","Speed: 2.2ms preprocess, 9.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8 cars, 1 truck, 17.8ms\n","Speed: 4.1ms preprocess, 17.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 13.7ms\n","Speed: 2.8ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 12.6ms\n","Speed: 2.1ms preprocess, 12.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 13.6ms\n","Speed: 2.6ms preprocess, 13.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 24.4ms\n","Speed: 2.7ms preprocess, 24.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 9 cars, 1 truck, 12.1ms\n","Speed: 2.4ms preprocess, 12.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 11.5ms\n","Speed: 2.3ms preprocess, 11.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 11.7ms\n","Speed: 2.5ms preprocess, 11.7ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 8 cars, 1 truck, 11.0ms\n","Speed: 2.3ms preprocess, 11.0ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 8 cars, 1 truck, 10.6ms\n","Speed: 2.5ms preprocess, 10.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 9 cars, 1 truck, 10.8ms\n","Speed: 2.2ms preprocess, 10.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 9 cars, 1 truck, 16.7ms\n","Speed: 2.4ms preprocess, 16.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 19.8ms\n","Speed: 2.3ms preprocess, 19.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 29.8ms\n","Speed: 2.2ms preprocess, 29.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 15.1ms\n","Speed: 2.5ms preprocess, 15.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 10.8ms\n","Speed: 2.4ms preprocess, 10.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 9 cars, 1 truck, 23.6ms\n","Speed: 4.7ms preprocess, 23.6ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 10 cars, 1 truck, 25.8ms\n","Speed: 2.3ms preprocess, 25.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 2 persons, 10 cars, 1 truck, 15.7ms\n","Speed: 4.1ms preprocess, 15.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 10 cars, 1 truck, 11.1ms\n","Speed: 2.3ms preprocess, 11.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 11 cars, 1 truck, 16.6ms\n","Speed: 3.6ms preprocess, 16.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 10.7ms\n","Speed: 2.8ms preprocess, 10.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 11.1ms\n","Speed: 2.8ms preprocess, 11.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 12.0ms\n","Speed: 2.8ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 11 cars, 1 truck, 10.8ms\n","Speed: 3.0ms preprocess, 10.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 12.5ms\n","Speed: 2.2ms preprocess, 12.5ms inference, 6.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 13.3ms\n","Speed: 2.3ms preprocess, 13.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 11.3ms\n","Speed: 3.4ms preprocess, 11.3ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 14.5ms\n","Speed: 8.7ms preprocess, 14.5ms inference, 16.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 13.9ms\n","Speed: 3.3ms preprocess, 13.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 12.6ms\n","Speed: 2.3ms preprocess, 12.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 12 cars, 1 truck, 8.2ms\n","Speed: 3.1ms preprocess, 8.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 6.9ms\n","Speed: 2.7ms preprocess, 6.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 10 cars, 1 truck, 7.0ms\n","Speed: 2.4ms preprocess, 7.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","Видео сохранено как: tracking_result_20250606_100512.mp4\n"]}]},{"cell_type":"markdown","source":["## Используя код выше реализуйте задания ниже (все в одной общей задаче)"],"metadata":{"id":"cKZB175a2m49"}},{"cell_type":"markdown","source":["## Задача 1"],"metadata":{"id":"wQ12JW5luh7H"}},{"cell_type":"markdown","source":["Сделайте так, чтобы трекер работал только в заданной области (например, внутри прямоугольника [x1, y1, x2, y2])."],"metadata":{"id":"TYQs6z8Fukja"}},{"cell_type":"markdown","source":["## Задача 2"],"metadata":{"id":"AAgExYmnuvp1"}},{"cell_type":"markdown","source":["Сделайте так, чтобы цвет bbox менялся в зависимости от misses"],"metadata":{"id":"Qym_FKWRuymC"}},{"cell_type":"markdown","source":["## Задача 3"],"metadata":{"id":"zxnhvWWu1vuW"}},{"cell_type":"markdown","source":["Добавьте трекам поле history, хранящее последние N координат, и визуализируйте их с ниспадающей яркостью"],"metadata":{"id":"v2fyy_p22Saf"}},{"cell_type":"markdown","source":["## Задача 4"],"metadata":{"id":"WkqKUFVi2ale"}},{"cell_type":"markdown","source":["Выводите для кадра:\n","1. Число активных треков.\n","2. Среднюю скорость движения (пикселей/кадр) для каждого объекта."],"metadata":{"id":"36j10skA2cbe"}}]}